{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7748b08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import setGPU, numpy as np, glob, csv\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch, torch.nn as nn, torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a01d603",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "BERT_NAMES = ['bert-base-german-cased', \n",
    "             'bert-base-german-dbmdz-cased', \n",
    "             'bert-base-german-dbmdz-uncased', \n",
    "             'distilbert-base-german-cased',\n",
    "            ]\n",
    "SOURCE_PATH = '../../Dataset/Text-Data/*-folds.csv'\n",
    "TARGET_PATH = '../../Dataset/Embeddings/{}-{}.npz'\n",
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b424304",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for bert_name in BERT_NAMES:\n",
    "    print('### Load Model: {}...'.format(bert_name))\n",
    "    bert_model = BertModel.from_pretrained(bert_name, hidden_dropout_prob=0.).to(DEVICE).eval()\n",
    "    bert_tokenizer = BertTokenizer.from_pretrained(bert_name)\n",
    "    for source in glob.glob(SOURCE_PATH):\n",
    "        ### Define usefull variables..\n",
    "        target = TARGET_PATH.format(source.split('/')[-1][:-4], bert_name)\n",
    "        encodings = []\n",
    "        labels = []\n",
    "        five_folds = []\n",
    "        ten_folds = []\n",
    "        train_test_split = []\n",
    "        embeddings = []\n",
    "        \n",
    "        ### Load Data from csv\n",
    "        print('Load Dataset: {}...'.format(source.split('/')[-1]))\n",
    "        with open(source, encoding=\"utf-8\") as f_source:\n",
    "            reader = csv.DictReader(f_source)\n",
    "            for row in reader:\n",
    "                encodings.append(row['text'])\n",
    "                labels.append(float(row['label']))\n",
    "                five_folds.append(int(row['five_folds']))\n",
    "                ten_folds.append(int(row['ten_folds']))\n",
    "                train_test_split.append(int(row['train_test_split']))\n",
    "        \n",
    "        ### Prepare Encodings and execute Bert\n",
    "        print('Execute Bert...')\n",
    "        encodings = bert_tokenizer(encodings, truncation=True, padding=True)\n",
    "        for idx in range(len(encodings['input_ids'])):\n",
    "            inp = {key : torch.tensor(val[idx]).unsqueeze(0).to(DEVICE) for key, val in encodings.items()}\n",
    "            with torch.no_grad():\n",
    "                emb = bert_model(**inp)['pooler_output'].cpu().numpy()[0]\n",
    "                embeddings.append(emb)\n",
    "        \n",
    "        ### Postprocessing and save data\n",
    "        print('Savez Dataset: {}'.format(target))\n",
    "        embeddings = np.stack(embeddings)\n",
    "        labels = np.array(labels)\n",
    "        five_folds = np.array(five_folds)\n",
    "        ten_folds = np.array(ten_folds)\n",
    "        train_test_split = np.array(train_test_split)\n",
    "        np.savez_compressed(target, \n",
    "                            embeddings=embeddings, \n",
    "                            labels=labels, \n",
    "                            five_folds=five_folds,\n",
    "                            ten_folds=ten_folds,\n",
    "                            train_test_split=train_test_split\n",
    "                           )\n",
    "    del bert_model, bert_tokenizer\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1abdaf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c949b265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f68a87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6405b418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c333de67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
